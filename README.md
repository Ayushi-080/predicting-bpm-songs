# ğŸµ Predicting BPM of Songs | Kaggle Playground S5E9

## ğŸ“– Project Overview

This project is my take on the **Kaggle Playground Series â€“ Season 5, Episode 9**, where the challenge was to **predict the Beats Per Minute (BPM)** of songs based on their audio features.
I approached it as a complete **end-to-end machine learning pipeline**, transforming raw tabular data into meaningful predictions â€” almost like turning data into music.  
From **EDA and feature engineering** to **model tuning and evaluation**, every step was a performed carefully.

---

## ğŸš€ Step-by-Step Journey

### 1ï¸âƒ£ Exploring the Data
I began by diving into the dataset â€” understanding distributions, correlations, and hidden rhythms behind the numbers.  
ğŸ“Š Used **Pandas**, **NumPy**, and **Seaborn** to visualize trends and spot patterns in acoustic features.

### 2ï¸âƒ£ Feature Engineering
To prepare the data for modeling:
- Encoded categorical variables like song type and genre ğŸ¼  
- Normalized and scaled numerical columns  
- Experimented with removing outliers that created â€œnoiseâ€ in the data  

### 3ï¸âƒ£ Model Building & Tuning
I tested and compared multiple models:
- **Linear Regression** â€“ as a baseline  
- **Random Forest Regressor** â€“ for non-linear feature handling  
- **XGBoost** & **CatBoost** â€“ for optimized gradient boosting performance  

ğŸ§© Finally, **CatBoost** gave the best results, handling categorical variables elegantly and producing smooth predictions.

### 4ï¸âƒ£ Evaluation
Evaluated models using **Root Mean Squared Error (RMSE)** to measure prediction accuracy.  
Visualized residuals to ensure the model didnâ€™t â€œoverfitâ€ to any specific tempo range.

ğŸ¯ **Result:** Achieved a strong performance with low RMSE, showing the model learned real BPM patterns effectively.

---

## ğŸ“ˆ Insights & Learnings

ğŸ”¹ **Feature Importance:**  
Energy, loudness, and tempo emerged as key predictors of BPM â€” proving how acoustic intensity relates directly to rhythm.

ğŸ”¹ **Takeaways:**  
- Learned how even synthetic tabular datasets can represent real-world musical patterns.  
- Strengthened intuition around model interpretability & cross-validation.  
- Improved hands-on experience with hyperparameter tuning & performance benchmarking.

---

## ğŸ§  Skills Demonstrated

| Area | What I Did |
|------|-------------|
| **Data Exploration & Cleaning** | Explored data patterns using Pandas & Seaborn |
| **Feature Engineering** | Encoded categorical features, scaled and normalized data |
| **Model Development** | Implemented and tuned Linear, RF, XGBoost & CatBoost models |
| **Evaluation** | Compared models via RMSE, analyzed residuals |
| **Visualization** | Created correlation maps & feature importance plots |
| **End-to-End ML Pipeline** | Built complete workflow from raw data â†’ prediction â†’ submission |

---

## âš™ï¸ Tech Stack

**Languages & Tools:** Python ğŸ, Jupyter Notebook ğŸ““  
**Libraries:** Pandas Â· NumPy Â· Matplotlib Â· Seaborn Â· Scikit-learn Â· XGBoost Â· CatBoost  
**Environment:** Kaggle Notebooks / Local Jupyter  

---

## ğŸ’¡ Reflections

Working on this project felt like balancing **data and rhythm** â€”  
each feature had its own beat, and tuning the model was like composing harmony between **noise and signal**.  

It wasnâ€™t just about predicting numbers â€” it was about learning to **listen to the data**.  
This challenge helped me strengthen my analytical thinking and storytelling with data, both essential for real-world ML roles.

---

## ğŸ‘©â€ğŸ’» Author

**Ayushi Mittal**  
ğŸ“ M.Tech in Computer Science (Artificial Intelligence)  
ğŸ‘©â€ğŸ« Data Scientist | Data Analyst | ğŸ§  Machine Learning & Data Science Enthusiast  

ğŸŒ [GitHub Profile](https://github.com/Ayushi-080)  
ğŸ“Š [Kaggle Profile](https://www.kaggle.com/pihu09876)  
ğŸ’Œ Open to collaborations and data-driven opportunities  

---

â­ *If you enjoyed this project or found it insightful, feel free to star the repo and connect!*
